{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "This notebook reproduces table 1 and figure 4 of the paper : Amortized Tree Generation for Bottom-up Synthesis Planning and Synthesizable Molecular Design."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import rdkit.Chem as Chem\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem import PandasTools\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "                                             targets  \\\n0  COc1cc(Cn2c(C)c(Cc3ccccc3)c3c2CCCC3)ccc1OCC(=O...   \n1             CCC1CCCC(Nc2cc(C(F)(F)F)c(Cl)cc2SC)CC1   \n2      Clc1cc(Cl)c(C2=NC(c3cccc4c(Br)cccc34)=NN2)nn1   \n3  COc1ccc(S(=O)(=O)c2ccc(-c3nc(-c4cc(B(O)O)ccc4O...   \n4  CNS(=O)(=O)c1ccc(-c2cc3c4c(ccc3[nH]2)CCCN4C(N)...   \n\n                                             decoded  similarity  \n0  COc1cc(Cn2c(C)c(Cc3ccccc3)c3c2CCCC3)ccc1OCC(=O...    1.000000  \n1                                                NaN    0.000000  \n2      Clc1cc(Cl)c(C2=NC(c3cccc4c(Br)cccc34)=NN2)nn1    1.000000  \n3  COc1ccc(S(=O)(=O)c2ccc(-c3nc(-c4cc(B(O)O)ccc4O...    1.000000  \n4  CNS(=O)(=O)c1ccc(-c2cc3cc4c(cc3[nH]2)N(C(N)=O)...    0.677419  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>targets</th>\n      <th>decoded</th>\n      <th>similarity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>COc1cc(Cn2c(C)c(Cc3ccccc3)c3c2CCCC3)ccc1OCC(=O...</td>\n      <td>COc1cc(Cn2c(C)c(Cc3ccccc3)c3c2CCCC3)ccc1OCC(=O...</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>CCC1CCCC(Nc2cc(C(F)(F)F)c(Cl)cc2SC)CC1</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Clc1cc(Cl)c(C2=NC(c3cccc4c(Br)cccc34)=NN2)nn1</td>\n      <td>Clc1cc(Cl)c(C2=NC(c3cccc4c(Br)cccc34)=NN2)nn1</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>COc1ccc(S(=O)(=O)c2ccc(-c3nc(-c4cc(B(O)O)ccc4O...</td>\n      <td>COc1ccc(S(=O)(=O)c2ccc(-c3nc(-c4cc(B(O)O)ccc4O...</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>CNS(=O)(=O)c1ccc(-c2cc3c4c(ccc3[nH]2)CCCN4C(N)...</td>\n      <td>CNS(=O)(=O)c1ccc(-c2cc3cc4c(cc3[nH]2)N(C(N)=O)...</td>\n      <td>0.677419</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data resulting from synthesis planning\n",
    "data = pd.read_csv(\"../results/demo-inference/decoded_results.csv.gz\", compression='gzip')\n",
    "data.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Inspired from script \"23-evaluate-predictions.py\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Clean-up the data, separating recovered (similarity =1) from unrecovered (similarity $\\in ]0,1[$) and discarding NaNs (similarity = 0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating file: ../results/demo-inference/decoded_results.csv.gz\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tdc import Evaluator\n",
    "\n",
    "\"Dataframe with target- and prediction smiles and similarities (*.csv.gz).\"\n",
    "input_file = \"../results/demo-inference/decoded_results.csv.gz\"\n",
    "\n",
    "\n",
    "# Keep track of successfully and unsuccessfully recovered molecules\n",
    "recovered = pd.DataFrame({\"targets\": [], \"decoded\": [], \"similarity\": []})\n",
    "unrecovered = pd.DataFrame({\"targets\": [], \"decoded\": [], \"similarity\": []})\n",
    "\n",
    "# load each file containing the predictions\n",
    "similarity = []\n",
    "n_recovered = 0\n",
    "n_unrecovered = 0\n",
    "n_total = 0\n",
    "files = [input_file]  # TODO: not sure why the loop but let's keep it for now\n",
    "for file in files:\n",
    "    print(f\"Evaluating file: {file}\")\n",
    "\n",
    "    result_df = pd.read_csv(file)\n",
    "    n_total += len(result_df[\"decoded\"])\n",
    "\n",
    "    # Split smiles, discard NaNs\n",
    "    is_recovered = result_df[\"similarity\"] == 1.0\n",
    "    unrecovered = pd.concat([unrecovered, result_df[~is_recovered].dropna()], ignore_index=True)\n",
    "    recovered = pd.concat([recovered, result_df[is_recovered].dropna()], ignore_index=True)\n",
    "\n",
    "    n_recovered += len(recovered)\n",
    "    n_unrecovered += len(unrecovered)\n",
    "    similarity += unrecovered[\"similarity\"].tolist()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "                                             targets  \\\n0  CNS(=O)(=O)c1ccc(-c2cc3c4c(ccc3[nH]2)CCCN4C(N)...   \n1  CC(NC(=O)C1Cn2c(O)nnc2CN1)c1cc(F)ccc1N1CCC(n2n...   \n2   CCCn1c(C)nnc1CC(C)(O)C(=C(C)C)c1nccnc1S(=O)(=O)F   \n3               CN(c1ccccc1)c1ccc(-c2nc3ncccc3s2)cn1   \n4  COc1cc(-c2nc(-c3ccc(F)cc3)c(-c3ccc(F)cc3)n2c2c...   \n\n                                             decoded  similarity  \n0  CNS(=O)(=O)c1ccc(-c2cc3cc4c(cc3[nH]2)N(C(N)=O)...    0.677419  \n1  CC(O)c1nnnn1CC1CCN(c2ccc(NC(=O)C3CCc4nnc(-c5cc...    0.286885  \n2  CCCn1c(C)nnc1CC(O)(c1nccnc1S(=O)(=O)F)c1ncnn1C...    0.590909  \n3     CN(c1ccccc1)c1ccc(C2=NC(c3nsc4cccnc34)=NN2)cn1    0.500000  \n4  COc1cc(-c2nc(-c3ccc(F)cc3)c(-c3ccc(F)cc3)n2c2c...    0.898734  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>targets</th>\n      <th>decoded</th>\n      <th>similarity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>CNS(=O)(=O)c1ccc(-c2cc3c4c(ccc3[nH]2)CCCN4C(N)...</td>\n      <td>CNS(=O)(=O)c1ccc(-c2cc3cc4c(cc3[nH]2)N(C(N)=O)...</td>\n      <td>0.677419</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>CC(NC(=O)C1Cn2c(O)nnc2CN1)c1cc(F)ccc1N1CCC(n2n...</td>\n      <td>CC(O)c1nnnn1CC1CCN(c2ccc(NC(=O)C3CCc4nnc(-c5cc...</td>\n      <td>0.286885</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>CCCn1c(C)nnc1CC(C)(O)C(=C(C)C)c1nccnc1S(=O)(=O)F</td>\n      <td>CCCn1c(C)nnc1CC(O)(c1nccnc1S(=O)(=O)F)c1ncnn1C...</td>\n      <td>0.590909</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>CN(c1ccccc1)c1ccc(-c2nc3ncccc3s2)cn1</td>\n      <td>CN(c1ccccc1)c1ccc(C2=NC(c3nsc4cccnc34)=NN2)cn1</td>\n      <td>0.500000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>COc1cc(-c2nc(-c3ccc(F)cc3)c(-c3ccc(F)cc3)n2c2c...</td>\n      <td>COc1cc(-c2nc(-c3ccc(F)cc3)c(-c3ccc(F)cc3)n2c2c...</td>\n      <td>0.898734</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unrecovered"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Compute N = number of molecules used, Recovery Rate, Average Similarity, KL Divergence, FC Distance"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N total 10\n",
      "Recovery rate 0.40%\n",
      "N finished tree 9 (0.90%)\n",
      "Average similarity (unrecovered only) 0.5907895737729258\n",
      "Evaluation metric for kl_divergence:\n",
      "    Recovered score: 1.00\n",
      "  Unrecovered score: 0.59\n",
      "Evaluation metric for fcd_distance:\n",
      "    Recovered score: -0.00\n",
      "  Unrecovered score: 18.28\n"
     ]
    }
   ],
   "source": [
    "# Print general info\n",
    "print(f\"N total {n_total}\")\n",
    "recovery_rate = n_recovered/n_total\n",
    "print(f\"Recovery rate {recovery_rate:.2f}%\")\n",
    "\n",
    "n_finished = n_recovered + n_unrecovered\n",
    "n_unfinished = n_total - n_finished\n",
    "print(f\"N finished tree {n_finished} ({n_finished/n_total:.2f}%)\")\n",
    "\n",
    "average_similarity = np.mean(similarity)\n",
    "print(f\"Average similarity (unrecovered only) {average_similarity}\")\n",
    "\n",
    "temp = []\n",
    "# Evaluate on TDC evaluators\n",
    "for metric in \"KL_divergence FCD_Distance\".split():\n",
    "    evaluator = Evaluator(name=metric)\n",
    "    try:\n",
    "        score_recovered = evaluator(recovered[\"targets\"], recovered[\"decoded\"])\n",
    "        score_unrecovered = evaluator(unrecovered[\"targets\"], unrecovered[\"decoded\"])\n",
    "    except TypeError:\n",
    "        # Some evaluators only take 1 input args, try that.\n",
    "        score_recovered = evaluator(recovered[\"decoded\"])\n",
    "        score_unrecovered = evaluator(unrecovered[\"decoded\"])\n",
    "    except Exception as e:\n",
    "        logger.error(f\"{e.__class__.__name__}: {str(e)}\")\n",
    "        logger.error(e)\n",
    "        score_recovered, score_unrecovered = np.nan, np.nan\n",
    "\n",
    "    print(f\"Evaluation metric for {evaluator.name}:\")\n",
    "    print(f\"    Recovered score: {score_recovered:.2f}\")\n",
    "    temp.append(score_recovered)\n",
    "    print(f\"  Unrecovered score: {score_unrecovered:.2f}\")\n",
    "    temp.append(score_unrecovered)\n",
    "\n",
    "kl_divergence = temp[0:2]\n",
    "fc_distance = temp[2:4]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "N                      10.000000\nRecovery Rate           0.400000\nAverage Similarity      0.590790\nKL Divergence           1.000000\nFC Distance            -0.000021\ndtype: float64"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {\"N\": n_total, \"Recovery Rate \": recovery_rate, \"Average Similarity \": average_similarity, \"KL Divergence \": kl_divergence[0], \"FC Distance \": fc_distance[0]}\n",
    "pd.Series(data=d)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "TODO: reproduce figure 4"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "conda-env-synnet-py",
   "language": "python",
   "display_name": "Python [conda env:synnet] *"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
